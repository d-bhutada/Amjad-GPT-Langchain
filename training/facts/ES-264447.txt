[ES-264447] CDC not retrieving as expected Created: 28/Jan/22  Updated: 26/Sep/22  Resolved: 04/May/22 Status:ResolvedProject:Engineering SupportComponents:Spark.Delta Affects versions:n/a Fix versions:dbr-11.0.0, dbr-10.5.1 Type: Incident Reporter: Sunando Bhattacharya (Support) Assignee: Rajesh Parangi Sharabhalingappa (Engineering - Central) Resolution: Fixed Votes: 1 Labels: created-from-cset, raised-by-support-team, scp-customer-impacted Remaining Estimate:Not Specified Time Spent:Not Specified Original estimate:Not Specified Attachments: Pasted Graphic 104-20220223-141425.png     Issue links: Duplicateis duplicated by ES-272075 Tmobile - CDF query throws NoSuchElem... Resolved is duplicated by ES-278631 Unable to time travel in delta table Resolved Incident Followupsfollow on work SC-107878 Generate continuation tokens for file... Open Relatesrelates to ES-82687 Delta Cannot Time Travel After Alteri... Resolved relates to ES-272075 Tmobile - CDF query throws NoSuchElem... Resolved relates to LS-220 Ensure time travel eventually gets fi... To Do relates to ES-272075 Tmobile - CDF query throws NoSuchElem... Resolved relates to ES-278631 Unable to time travel in delta table Resolved relates to ES-286055 Apple PVC: java.io.FileNotFoundExcept... Resolved relates to ES-287695 Spark structured streaming failing to... Resolved relates to ES-307163 T-Mobile - Query throws NoSuchElement... Resolved Support Severity Level:SEV2 Standard-Non-Critical Environment Type:AWS Multi-tenant Shard Name / Workspace ID:1763186605003310 Eng-Team:Streaming/Delta Sprint:Regression:No Salesforce Case Number:00130687, 00134989, 00136908, 00139838, 00158433Salesforce Case Number(s):[00130687 view] [00134989 view] [00136908 view] [00139838 view] [00158433 view] External Customer Facing?:Yes Outage end time:28/Apr/22 3:30 AM Outage start time:28/Jan/22 12:07 PM  Description   %sql select * from assetmdm_prd_hds.EQP_EQUIPMENT version as of 1197com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: com.databricks.sql.transaction.tahoe.VersionNotFoundException: Cannot time travel Delta table to version 1197. Available versions: [1310, 1386]. at com.databricks.sql.transaction.tahoe.DeltaHistoryManager.checkVersionExists(DeltaHistoryManager.scala:167) at ...Expected BehaviourTime travel should be possible.Action TakenFrontline Triage: ----------------------------------checked delta history %scala display(spark.sql("desc history assetmdm_prd_hds.EQP_EQUIPMENT"))jsons available for 1190 and 1197 but checkpoint file is missingthe earliest checkpoint available : 1160 -----------------------------------------%scala dbutils.fs.ls("gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log").filter(r=>r.name.contains("checkpoint")).map(l=>l.path.toString)res0: Seq[String] = ArrayBuffer(gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log/_last_checkpoint, gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log/00000000000000001160.checkpoint.parquet, gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log/00000000000000001390.checkpoint.parquet, gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log/00000000000000001400.checkpoint.parquet, gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log/00000000000000001410.checkpoint.parquet, ...the earliest json available: 1169 ------------------------------------------- %scala dbutils.fs.ls("gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log").filter(r=>r.name.contains("json")).map(l=>l.path.toString)ArrayBuffer(gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log/00000000000000001169.json, gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log/00000000000000001170.json, gs://jbh-datalake-prd/bronze/qlik_hds/assetmdm_prd_hds/eqp_equipment/_delta_log/00000000000000001171.json, ...)we see some jsons also missing. We checked if the customer had changed any delta log / checkpoint related configs from table history. - Customer replied they did not change any such settings. We wanted to check with you when this kind of situation may arise. Let me know if any further details is required.Test Notebook: https://1763186605003310.0.gcp.databricks.com/?o=1763186605003310#notebook/2763697937847490/command/2763697937847496Test Cluster: https://1763186605003310.0.gcp.databricks.com/?o=1763186605003310#setting/clusters/0121-162200-say904/configuration We even tried to generate the missing checkpoints but due to gap in json that is not possible.Steps to Reproducesimply run %sql select * from assetmdm_prd_hds.EQP_EQUIPMENT version as of 1197Note customer is not running vacuum but as we know vacuum only affects datafile  Comments   Comment by Genie Service Account [ 01/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Genie Service Account [ 02/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToGcpWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Genie Service Account [ 02/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToGcpWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Genie Service Account [ 03/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToGcpWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Genie Service Account [ 04/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToGcpWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Mathan Pillai (Support) [ 05/Feb/22 ] Meng Tong Any update on this?Here are the details on the similar issue that was reported by another customer. Please let me know if you need any more details from this newly reported issue that may help you in debugging the issue.https://databricks.slack.com/archives/C9D7ZT332/p1643760399861109For the new issue : In the meanwhile I tried querying logfood for terms like %FS_OP_DELETE%checkpoint% , %FS_OP_DELETE%json%, %FS_OP_DELETE% to see if they have deleted any files on that table (ps_ws_manager). But it looks like the query returns no results. So none of the customer’s jobs have deleted any of the files from their tables, at least after 2022-01-01Comment by Sunando Bhattacharya (Support) [ 07/Feb/22 ] Hi Meng Tong ,Is there any update that can be shared with the customer?Comment by Genie Service Account [ 07/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToGcpWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Meng Tong (Inactive) [ 07/Feb/22 ] Sunando Bhattacharya (Support) When checking the logs for this issue, I could only see the logs for the vacuum job. This indicates that the other write operations on this table are done in a different workspace in a different region that the one provided in the ticket. Could you ask the customer to get the link for that workspace so that I could fetch the corresponding logs?Comment by Sunando Bhattacharya (Support) [ 07/Feb/22 ] Hi Meng Tong ,Can you check https://6354819927873507.7.gcp.databricks.com/?o=6354819927873507#notebook/1612566811046991/command/3178344272395229 as well?As per customer:Only one notebook load data(load around 1000 tables iteratively). Its a tool that was developed. In a different workspace. All operations are merge.https://6354819927873507.7.gcp.databricks.com/?o=6354819927873507#notebook/1612566811046991/command/3178344272395229Comment by Genie Service Account [ 08/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToGcpWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Meng Tong (Inactive) [ 08/Feb/22 ] Log cleanup details for related versions from 1150 to 12502021-11-11T00:01:57.810+0000{   "commitVersionToDeleteUntilOpt":463,   "checkpointVersionToDeleteUntilOpt":1090,   "latestCheckpointVersion":1150,   "enableFullRetentionRollback":true,   "earliestCommitVersion":442,   "earliestCommitTimestamp":1633913416010,   "latestCommitVersionBeforeCutoff":462,   "latestCommitTimestampBeforeCutoff":1633994938881,   "earliestCheckpointVersion":30,   "earliestCheckpointTimestamp":1627531487452,   "latestCheckpointVersionBeforeCommitCutoff":30,   "latestCheckpointTimestampBeforeCommitCutoff":1627531487452,   "latestCheckpointVersionBeforeCutoff":1090,   "latestCheckpointTimestampBeforeCutoff":1636387260742}2021-11-11T10:00:41.180+0000{   "checkpointVersionToDeleteUntilOpt":1090,   "latestCheckpointVersion":1160,   "enableFullRetentionRollback":true,   "earliestCheckpointVersion":30,   "earliestCheckpointTimestamp":1627531487452,   "latestCheckpointVersionBeforeCommitCutoff":30,   "latestCheckpointTimestampBeforeCommitCutoff":1627531487452,   "latestCheckpointVersionBeforeCutoff":1090,   "latestCheckpointTimestampBeforeCutoff":1636387260742}2021-11-12 02:20:24.522 commit 11662021-12-16T18:06:21.405+0000 commit 11672022-01-12T19:25:20.713+0000{   "commitVersionToDeleteUntilOpt":1167,   "checkpointVersionToDeleteUntilOpt":1160,   "latestCheckpointVersion":1170,   "enableFullRetentionRollback":true,   "earliestCommitVersion":463,   "earliestCommitTimestamp":1633997827920,   "latestCommitVersionBeforeCutoff":1166,   "latestCommitTimestampBeforeCutoff":1636648764058,   "earliestCheckpointVersion":30,   "earliestCheckpointTimestamp":1627531487452,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1160,   "latestCheckpointTimestampBeforeCutoff":1636624840343,   "createdCheckpointAtVersion":1167}2022-01-13T03:18:47.596+0000{   "commitVersionToDeleteUntilOpt":1167,   "checkpointVersionToDeleteUntilOpt":1160,   "latestCheckpointVersion":1180,   "enableFullRetentionRollback":true,   "earliestCommitVersion":1161,   "earliestCommitTimestamp":1636628019159,   "latestCommitVersionBeforeCutoff":1166,   "latestCommitTimestampBeforeCutoff":1636648764058,   "earliestCheckpointVersion":1160,   "earliestCheckpointTimestamp":1636624840343,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1160,   "latestCheckpointTimestampBeforeCutoff":1636624840343,   "createdCheckpointAtVersion":1167}2022-01-13T13:26:09.719+0000{   "checkpointVersionToDeleteUntilOpt":1160,   "latestCheckpointVersion":1190,   "enableFullRetentionRollback":true,   "earliestCheckpointVersion":1160,   "earliestCheckpointTimestamp":1636624840343,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1160,   "latestCheckpointTimestampBeforeCutoff":1636624840343}2022-01-14T05:23:31.288+0000{   "checkpointVersionToDeleteUntilOpt":1160,   "latestCheckpointVersion":1200,   "enableFullRetentionRollback":true,   "earliestCheckpointVersion":1160,   "earliestCheckpointTimestamp":1636624840343,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1160,   "latestCheckpointTimestampBeforeCutoff":1636624840343}2022-01-14T14:33:03.123+0000{   "checkpointVersionToDeleteUntilOpt":1160,   "latestCheckpointVersion":1210,   "enableFullRetentionRollback":true,   "earliestCheckpointVersion":1160,   "earliestCheckpointTimestamp":1636624840343,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1160,   "latestCheckpointTimestampBeforeCutoff":1636624840343}2022-01-15T00:29:29.450+0000{   "checkpointVersionToDeleteUntilOpt":1170,   "latestCheckpointVersion":1220,   "enableFullRetentionRollback":true,   "earliestCheckpointVersion":1160,   "earliestCheckpointTimestamp":1636624840343,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1170,   "latestCheckpointTimestampBeforeCutoff":1642015461393}2022-01-15T09:33:10.783+0000{   "checkpointVersionToDeleteUntilOpt":1170,   "latestCheckpointVersion":1230,   "enableFullRetentionRollback":true,   "earliestCheckpointVersion":1160,   "earliestCheckpointTimestamp":1636624840343,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1170,   "latestCheckpointTimestampBeforeCutoff":1642015461393}2022-01-15T19:18:33.157+0000{   "checkpointVersionToDeleteUntilOpt":1170,   "latestCheckpointVersion":1240,   "enableFullRetentionRollback":true,   "earliestCheckpointVersion":1160,   "earliestCheckpointTimestamp":1636624840343,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1170,   "latestCheckpointTimestampBeforeCutoff":1642015461393}2022-01-16T04:29:59.242+0000{   "state":{      "commitVersionToDeleteUntilOpt":1169,      "checkpointVersionToDeleteUntilOpt":1190,      "latestCheckpointVersion":1250,      "enableFullRetentionRollback":true,      "earliestCommitVersion":1167,      "earliestCommitTimestamp":1639677980343,      "latestCommitVersionBeforeCutoff":1168,      "latestCommitTimestampBeforeCutoff":1639678442637,      "earliestCheckpointVersion":1160,      "earliestCheckpointTimestamp":1636624840343,      "latestCheckpointVersionBeforeCommitCutoff":1160,      "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,      "latestCheckpointVersionBeforeCutoff":1190,      "latestCheckpointTimestampBeforeCutoff":1642080369324   },   "exception":"requirement failed: Did not get the first delta file version: 1161 to compute Snapshot"}2022-01-16T04:29:59.602+0000{   "commitVersionToDeleteUntilOpt":1169,   "checkpointVersionToDeleteUntilOpt":1190,   "latestCheckpointVersion":1250,   "enableFullRetentionRollback":true,   "earliestCommitVersion":1167,   "earliestCommitTimestamp":1639677980343,   "latestCommitVersionBeforeCutoff":1168,   "latestCommitTimestampBeforeCutoff":1639678442637,   "earliestCheckpointVersion":1160,   "earliestCheckpointTimestamp":1636624840343,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1190,   "latestCheckpointTimestampBeforeCutoff":1642080369324}2022-01-16T16:20:58.341+0000{   "checkpointVersionToDeleteUntilOpt":1190,   "latestCheckpointVersion":1260,   "enableFullRetentionRollback":true,   "earliestCheckpointVersion":1160,   "earliestCheckpointTimestamp":1636624840343,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1190,   "latestCheckpointTimestampBeforeCutoff":1642080369324}Comment by Meng Tong (Inactive) [ 08/Feb/22 ] Based on the logs, the history of the table looks like below:1160: 2021-11-11T10:00:41.180+00001166: 2021-11-12 02:20:24.5221167: 2021-12-16T18:06:21.405+00001168: 2021-12-16T18:15:51.781+00001169: 2022-01-12T19:24:14.474+00001170: 2022-01-12T19:25:20.713+0000 (json: 1167, 1168, 1169, 1170, checkpoint: 1160, 1167 (created), 1170)1180: 2022-01-13T03:18:47.596+0000 (json: 1167 → 1180, cp: 1160, 1167, 1170, 1180)1190: 2022-01-13T13:26:09.719+0000 (json: 1167 → 1190, cp: 1160, 1167, 1170, 1180)1200: 2022-01-14T05:23:31.288+0000 (json: 1167 → 1200, cp: 1160, 1167, 1170, 1180)1210: 2022-01-14T14:33:03.123+0000 (json: 1167 → 1210, cp: 1160, 1167, 1170, 1180)1220: 2022-01-15T00:29:29.450+0000 (json: 1167 → 1220, cp: 1160, 1170, 1180) (1167 deleted? wrong)Comment by Meng Tong (Inactive) [ 08/Feb/22 ] The problem seems to come from log clean up in version 1170:{   "commitVersionToDeleteUntilOpt":1167,   "checkpointVersionToDeleteUntilOpt":1160,   "latestCheckpointVersion":1170,   "enableFullRetentionRollback":true,   "earliestCommitVersion":463,   "earliestCommitTimestamp":1633997827920,   "latestCommitVersionBeforeCutoff":1166,   "latestCommitTimestampBeforeCutoff":1636648764058,   "earliestCheckpointVersion":30,   "earliestCheckpointTimestamp":1627531487452,   "latestCheckpointVersionBeforeCommitCutoff":1160,   "latestCheckpointTimestampBeforeCommitCutoff":1636624840343,   "latestCheckpointVersionBeforeCutoff":1160,   "latestCheckpointTimestampBeforeCutoff":1636624840343,   "createdCheckpointAtVersion":1167}in combination with the following logic:      state.checkpointVersionToDeleteUntilOpt.foreach { untilVersion =>        // The earliest checkpoint to keep is either:        //   1. The checkpoint that was just created for full retention        //   2. The latestCheckpointVersionBeforeCommitCutoff - if the version of this checkpoint        //      is the version before the earliest delta commit to keep, we don't create a new        //      checkpoint and `createdCheckpointAtVersion` is empty        //   3. The earliest checkpoint that exists may need to be kept, e.g. if we don't need to        //      delete any delta files. See ES-82687        //   4. If all else is empty, keep the latest checkpoint        val earliestCheckpointToKeep = state.createdCheckpointAtVersion          .orElse(state.latestCheckpointVersionBeforeCommitCutoff)          .orElse(state.earliestCheckpointVersion)          .getOrElse(latestCheckpoint.get.version)        // Any checkpoint that is just getting to the cutoff point can still be in use, so        // we should keep them as well        val activeCheckpoint = state.latestCheckpointVersionBeforeCutoff          .orElse(state.latestCheckpointVersionBeforeCommitCutoff)          .getOrElse(latestCheckpoint.get.version)        deleteExpiredCheckpoints(          cleanupTime,          earliestCheckpointToKeep,          activeCheckpoint,          untilVersion)      }we can see that we call deleteExpiredCheckpoints with the following:        deleteExpiredCheckpoints(          cleanupTime,          earliestCheckpointToKeep,  /* 1167 */          activeCheckpoint,  /* 1160 */          untilVersion)  /* 1160 */This will result in checkpoint 1160 being kept (and cause down stream logic to go wrong).The special part with this case is that there is a log gap between version 1166 (2021-11-12) and 1167 (2021-12-16) and the 30 days cut off when checkpoint 1170 happen to fall in this gap. This resulted in an untilVersion smaller than earliestCheckpointToKeep, which seems to be unexpected for deleteExpiredCheckpoints.Comment by Meng Tong (Inactive) [ 08/Feb/22 ] Logs are collected here https://5819292615799942.2.gcp.databricks.com/?o=5819292615799942#notebook/2710700552669843/command/2094955227352295Comment by Meng Tong (Inactive) [ 08/Feb/22 ] Need to run the analysis through some people to see if it makes sense.Comment by Sunando Bhattacharya (Support) [ 08/Feb/22 ] Hi Meng Tong ,Let us know if there is any progress.any recommendation which can be provided to the customer?Comment by Mathan Pillai (Support) [ 09/Feb/22 ] Meng Tong we had another issue reported by t-mobile stating that their prod job failed because of this issue. pls see below for more info. What is the best way to unblock the customer, to make the table working again ?https://databricks.slack.com/archives/C9D7ZT332/p1644434499711749Comment by Genie Service Account [ 10/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Genie Service Account [ 10/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Genie Service Account [ 10/Feb/22 ] Requestor: meng.tong@databricks.comAuthentication Type: loginToGcpWorkspaceWorkspace: 1763186605003310Duration: 10hReason: ES: 264447Comment by Genie Service Account [ 11/Feb/22 ] Requestor: rajesh.parangi@databricks.comAuthentication Type: loginToGcpWorkspaceWorkspace: 1763186605003310Duration: 1hReason: ES: 264447Comment by Sunando Bhattacharya (Support) [ 15/Feb/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central) ,Is there any further update on this ES?Comment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 15/Feb/22 ] I have been investigating this issue since Friday and have been able to come up with a theory. It appears that there is a subtle bug in the code which leads to this. I will discuss my findings with an engineer today afternoon and provide more updates here. Comment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 16/Feb/22 ] The bug is this: When we do log cleanup, we delete commit json and CRC files as well as checkpoint files. The logic to delete commit files need to take available checkpoint files into account. There are cases where commit files may get deleted even when the previous checkpoints are non-existent. We will soon have a PR to fix this. Comment by Ujjawal Kashyap (Support) [ 23/Feb/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central), We had a similar case reported by Prodigy Education where their prod job for CDC failed because of this issue when trying to read changes with the error: java.lang.IllegalArgumentException: requirement failed: Did not get the first delta file version: 127 to compute Snapshot(commit files are missing from version 127 to 305).Please advise on the workaround to mitigate this issue.Comment by Sunando Bhattacharya (Support) [ 01/Mar/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central) ,Is the PR deployed to the customer’s workspace? Please suggest us the next steps.Comment by Ujjawal Kashyap (Support) [ 04/Mar/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central), Customer from Prodigy Education reported another job failure where their non-CDC monthly job failed with Error: java.lang.IllegalArgumentException: requirement failed: Did not get the first delta file version: 11 to compute Snapshot.The commit files are missing from version 10 to version 143. The customer was able to run this monthly streaming job successfully after clearing the checkpoint directory to initiate a full sync to the snowflake model (from delta). Please provide your inputs on in what scenario the failed monthly job could run successfully after clearing the checkpoint directory and can this issue occur in non-CDC jobs also as in this case.SF ticket # 00134989Comment by Sunando Bhattacharya (Support) [ 08/Mar/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central) ,Is the fix pushed to the customer’s environment? The case is open in our queue for 47 days now.Comment by Ujjawal Kashyap (Support) [ 11/Mar/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central), Could you please let us know the ETA for this fix deployment? Comment by Sunando Bhattacharya (Support) [ 29/Mar/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central), Any updates on the PR review status?Comment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 04/Apr/22 ] The fix is more involved and is under discussion. Current ETA is at least two weeks from now. Look for updates on this channel every few days.Comment by Anthony Melnick (Paid CSE) [ 05/Apr/22 ] T-Mobile is also escalating this issue https://databricks.atlassian.net/browse/ES-272075 Comment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 19/Apr/22 ] The fix will be merged to master this week. Then I will backport the change to LTS versions. Since the change is complicated and involved, we may not be able to backport to all the versions. Is 10.4 LTS enough for all the customers affected?Comment by Sunando Bhattacharya (Support) [ 19/Apr/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central) ,Let me know when this change is merged I will recommend the customer to use 10.4 LTS once merged.Comment by Mohammad Subhani (Support) [ 19/Apr/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central) , Can this be back-ported to 9.1 LTS as there are many customers who prefer to stay on 9.1 LTS before migrating their Jobs to 10.4 LTS?Also, as we don't have enough data points on 10.4 LTS regression issues if any, it would be great if this can be backported to 9.1 LTS because of the same reasons. cc: Harikrishnan Kunhumveettil Comment by Ujjawal Kashyap (Support) [ 19/Apr/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central), The customer from Prodigy Education who is facing this issue is using 9.1 LTS, please let us know if this fix can be backported to 9.1 LTS also. Thanks.Comment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 20/Apr/22 ] Ok, I will attempt to merge the fix to both 10.4 and 9.1 LTS. If I face any issues, I will post it here. Expect to see an update in 24 hours.Comment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 21/Apr/22 ] All the backporting PRs are ready and I am waiting for the github checks to pass. Let me find out the next release date for 9.1 and 10.4 LTS.Comment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 22/Apr/22 ] The fix has been merged to 9.1 and 10.4 LTS and will be rolled out as part of the next release cycle. Comment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 27/Apr/22 ] During log cleanup, the current logic creates a new checkpoint as of the oldest commit version that we need to keep for time travel. Since checkpoints and commit files are subject to different retention periods (2 days for the former vs 30 days for the latter), the newly created checkpoint will become eligible for deletion after 2 days. if we delete it, we have no way to time travel to versions that are within the allowed time window since all the commit files before this checkpoint have been deleted assuming we have this checkpoint. The fix involves finding the earliest commit version within the valid window and ensuring that we always preserve the necessary checkpoint during log cleanup.Comment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 04/May/22 ] Fixed it through this PR : https://github.com/databricks/runtime/pull/38230 Comment by Sunando Bhattacharya (Support) [ 27/May/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central) ,This issue seems to be resurfaced for another customer 00158433. They are already using DBR 9.1. The URL of the issue notebook is: https://vitruvian-21e9-na-us-pp.cloud.databricks.com/?o=275579571380665#notebook/536328186054200/command/536328186054204The link for debug notebook is: https://vitruvian-21e9-na-us-pp.cloud.databricks.com/?o=275579571380665#notebook/4363094689448722/command/4363094689448723The latest checkpoint after which the customer sees continuous JSONs is 214. The 00000000000000000200.json file was created on 04th May 2022 at 16:40 hrs.I know this Fix was done roughly around April end so now the question is how can this happen? Comment by Mohammad Subhani (Support) [ 31/May/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central) and Rahul Mahadev (Engineering - Central) , can you kindly help us to review the above issue reported by Sunando Bhattacharya (Support). Comment by Sunando Bhattacharya (Support) [ 31/May/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central) ,Thank you for the insight on the deployment timelines for May 10.We will only report if we see a similar issue after June 15 based on the default logRetentionDuration.Comment by Noopur Nigam (Support) [ 04/Jul/22 ] Hi Rajesh Parangi Sharabhalingappa (Engineering - Central) It seems like the issue still persists as Parafin is facing the issue and using DBR 10.4 LTS. Case number: 00186273.Comment by Anthony Melnick (Paid CSE) [ 14/Jul/22 ] Rajesh Parangi Sharabhalingappa (Engineering - Central) T-Mobile is also reporting that is issue is still occuringComment by Rajesh Parangi Sharabhalingappa (Engineering - Central) [ 14/Jul/22 ] We have a new ticket for this: https://databricks.atlassian.net/browse/LS-220 Generated at Mon Mar 20 12:13:56 UTC 2023 by Deepak Bhutada using Jira 1001.0.0-SNAPSHOT#100218-sha1:fe49d35fe965a814efd7754d4cd0e99bc2088b37. 